# Plan Global: MVP PostgreSQL con Experimento Controlado de Embedders

## Contexto y Objetivo

### Problema a Resolver
El sistema RAG actual devuelve **chunks duplicados exactos** y muchos resultados irrelevantes, lo que lo hace no funcional para uso práctico.

### Objetivo Principal
Crear un **MVP PostgreSQL funcional** que resuelva el problema de duplicados y mejore la relevancia del retrieval, mediante un experimento controlado de diferentes embedders.

### Alcance
- **Duración:** 3 días principales + 1 día opcional de refactor
- **Enfoque:** Backend PostgreSQL únicamente (no migración desde SQLite)
- **Metodología:** Experimento controlado con mediciones objetivas
- **Resultado:** Selección de embedder óptimo y backend funcional

## Estrategia General

### Backends Separados
- **SQLite actual:** Congelar en modo solo lectura (no modificar datos existentes)
- **PostgreSQL nueva:** Base de datos `rag_experiments` completamente limpia
- **Ventaja:** Evitar contaminación de datos sucios y poder comparar limpia

### Experimento Controlado
- **Mismos datos:** 10-20 chunks representativos para todos los embedders
- **Mismas queries:** 5 preguntas de referencia estandarizadas
- **Métricas objetivas:** Tiempos, recursos, duplicados, relevancia
- **Cache invalidation:** Limpieza completa entre cambios de embedder

### Shortlist de Embedders
1. **all-MiniLM-L6-v2** (Control - actual)
   - Dimensión: 384
   - Idioma: Inglés básico
   - Calidad: Baseline

2. **all-mpnet-base-v2** (Mejor calidad)
   - Dimensión: 768
   - Idioma: Inglés mejorado
   - Calidad: Alta

3. **paraphrase-multilingual-MiniLM-L12-v2** (Multilingüe)
   - Dimensión: 384
   - Idioma: Multilingüe (excelente español)
   - Calidad: Media-alta

## Fases del Plan

### Fase 1: Setup PostgreSQL + Ingestión Controlada (Día 1)
**Objetivo:** Crear infraestructura limpia y validar ingesta con modelo base

**Duración:** 3-4 horas

**Entregables:**
- PostgreSQL + pgvector funcionando
- Schema paramétrico con EMBEDDING_DIM configurable
- 10-20 chunks ingeridos sin duplicados con embedder base
- Tiempos de ingestión registrados

**Documento detallado:** `Fase_1_Setup_Limpio.md`

### Fase 2: Experimento con Embedders Candidatos (Día 2)
**Objetivo:** Comparar rendimiento y calidad entre diferentes embedders

**Duración:** 4-5 horas

**Entregables:**
- Matriz de ingestión completada para los 3 embedders
- Métricas de rendimiento (tiempos, recursos, tamaños)
- Validación de que no hay duplicados en ningún caso
- Outputs crudos guardados para análisis

**Documento detallado:** `Fase_2_Experimento_Embedders.md`

### Fase 3: Validación Comparativa y Decisión (Día 3)
**Objetivo:** Ejecutar queries de prueba, comparar calidad y decidir embedder final

**Duración:** 4-5 horas

**Entregables:**
- 5 queries ejecutadas para cada embedder
- Matriz de decisión completa con puntuaciones
- Embedder final seleccionado con justificación
- Outputs crudos guardados para análisis futuro

**Documento detallado:** `Fase_3_Validacion_Decision.md`

### Fase 4: Refactor del Retriever (Opcional - Día 4)
**Objetivo:** Implementar backend definitivo con embedder seleccionado

**Duración:** 3-4 horas

**Condiciones:**
- Solo si Día 3 es exitoso
- Embedder final claramente superior
- Tiempo disponible para refactor

## Configuración Técnica

### Variables de Entorno Clave
```bash
# Backend PostgreSQL
DATABASE_BACKEND=postgresql
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=rag_experiments
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_password

# Embedding configurable
EMBEDDING_MODEL=all-MiniLM-L6-v2
EMBEDDING_DIM=384

# Experimentación
EXPERIMENT_MODE=true
SAVE_RAW_OUTPUTS=true
```

### Schema Paramétrico
```sql
-- Tabla documents con hash único
CREATE TABLE documents (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    content TEXT NOT NULL,
    source_hash VARCHAR(64) UNIQUE NOT NULL,
    chunking_strategy VARCHAR(50) DEFAULT 'agentic',
    embedding_model VARCHAR(100),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Tabla embeddings con dimensión paramétrica
CREATE TABLE document_embeddings (
    id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
    document_id BIGINT REFERENCES documents(id) ON DELETE CASCADE,
    embedding vector(%EMBEDDING_DIM%),
    embedding_model VARCHAR(100),
    CHECK (array_length(embedding, 1) = %EMBEDDING_DIM%),
    UNIQUE(document_id)
);
```

### Cache Invalidation Strategy
Para cada cambio de `EMBEDDING_DIM`:
1. **Limpiar cache de modelos:** `rm -rf ~/.cache/torch/sentence_transformers/`
2. **Limpiar base de datos:** `DROP TABLE` y recrear schema
3. **Reconstruir embeddings:** Nueva instancia del modelo
4. **Re-procesar chunks:** Desde cero para cada embedder

## Queries de Referencia

### Dataset de Prueba (5 queries)
1. **Query Técnica:** "¿Qué es Docker y cómo funciona?"
2. **Query Proceso:** "¿Cómo se instala PostgreSQL?"
3. **Query Definición:** "¿Qué son los embeddings?"
4. **Query Práctica:** "¿Para qué sirve el chunking?"
5. **Query Ambigua:** "Sistemas de bases de datos"

### Métricas por Query
- **Duplicados:** Número de resultados idénticos (esperado: 0)
- **Relevancia:** Evaluación subjetiva 1-5
- **Tiempo respuesta:** Milisegundos
- **Orden correcto:** Los más relevantes primero

## Matriz de Decisión

### Criterios de Evaluación
| Criterio | Ponderación | Descripción |
|----------|-------------|-------------|
| Relevancia Promedio | 30% | Calidad de resultados (1-5) |
| Tiempo Respuesta | 25% | Latencia promedio (ms) |
| Recursos CPU | 15% | Consumo de procesamiento |
| Cobertura Español | 20% | Soporte para español |
| Tamaño BD | 10% | Espacio de almacenamiento |

### Plantilla de Matriz
| Embedder | Relevancia (30%) | Tiempo (25%) | CPU (15%) | Español (20%) | Tamaño (10%) | **Total (100%)** |
|----------|------------------|--------------|-----------|---------------|---------------|-------------------|
| MiniLM | TBD | TBD | TBD | TBD | TBD | **TBD** |
| MPNet | TBD | TBD | TBD | TBD | TBD | **TBD** |
| Multi | TBD | TBD | TBD | TBD | TBD | **TBD** |

## Criterios de Éxito

### Éxito del Proyecto
- ✅ PostgreSQL funciona sin duplicados
- ✅ Al menos un embedder supera claramente a los demás
- ✅ Tiempos de respuesta aceptables (< 500ms)
- ✅ Relevancia mejorada vs actual (subjetivo)
- ✅ Sistema listo para producción con backend seleccionado

### Fracaso del Proyecto
- ❌ PostgreSQL también genera duplicados
- ❌ Todos los embedders tienen rendimiento similar
- ❌ Ningún embedder mejora la relevancia actual
- ❌ Tiempos de respuesta inaceptables (> 2s)
- ❌ Problemas técnicos no resueltos

## Preparación para Ejecución

### Requisitos Previos
1. **PostgreSQL instalado** con pgvector
2. **Python environment** activado
3. **Dataset de prueba** disponible en transcripts_for_rag
4. **Dependencias** instaladas (psycopg, sentence-transformers)

### Comandos Iniciales
```bash
# Verificar instalación
psql --version
python --version

# Crear base de datos experimental
createdb rag_experiments

# Activar entorno virtual
source .venv/Scripts/activate

# Instalar dependencias (si es necesario)
pip install psycopg[binary,pool] sentence-transformers
```

### Validación Inicial
```bash
# Probar conexión PostgreSQL
psql -d rag_experiments -c "SELECT version();"

# Verificar pgvector
psql -d rag_experiments -c "CREATE EXTENSION IF NOT EXISTS vector;"

# Probar import de módulos
python -c "import psycopg; import sentence_transformers; print('Dependencies OK')"
```

## Documentos de Referencia

- **`Fase_1_Setup_Limpio.md`** - Detalles completos del Día 1
- **`Fase_2_Experimento_Embedders.md`** - Detalles completos del Día 2
- **`Fase_3_Validacion_Decision.md`** - Detalles completos del Día 3
- **`logs/`** - Directorio para outputs crudos y métricas
- **`results/`** - Directorio para matrices y análisis

## Timeline Resumido

```
Día 1 (3-4h): Setup PostgreSQL + Embedder base
├── Instalar PostgreSQL + pgvector
├── Crear schema paramétrico
├── Seleccionar dataset 10-20 chunks
└── Ingerir con MiniLM (384)

Día 2 (4-5h): Experimento embedders
├── Probar MPNet (768) - limpiar cache
├── Probar Multilingual (384) - limpiar cache
├── Registrar métricas de ingestión
└── Crear matriz de rendimiento

Día 3 (4-5h): Validación y decisión
├── Ejecutar 5 queries por embedder
├── Evaluar relevancia y tiempos
├── Completar matriz de decisión
└── Seleccionar embedder final

Día 4 (Opcional): Refactor
├── Implementar backend definitivo
├── Integrar con sistema actual
└── Testing completo
```

## Next Steps

1. **Revisar documentos de fase específicos** para detalles técnicos
2. **Verificar requisitos previos** (PostgreSQL, dependencias)
3. **Empezar con Fase 1** cuando estés listo
4. **Documentar resultados** en los logs previstos

El plan está diseñado para ser ejecutable paso a paso con checkpoints claros y criterios de éxito medibles.